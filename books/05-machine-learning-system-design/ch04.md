<div align="center">
    <h1>4장. 훈련 데이터</h1>
    <i>moderated by <a href="https://github.com/bsm8734">샐리</a></i>
</div>

## 📝 목차

- [💬 이야기 주제](#-이야기-주제)

(⭐️ 작성 후에 목차도 추가해주세요!)

---

## 4.1. 샘플링

- 샘플링을 하면 작업을 빠르게 수행할 수 있고, 비용이 줄어든다.

### 4.1.1. 비확률 샘플링

- 데이터를 확률이 아닌 기준에 의거해 선택하는 방법
- 실데이터를 잘 대표하지 못하고 선택 편향이 강하지만, 사용이 편리하여 많이 사용된다.

1. `편의 샘플링`: 가용성에 의거해 데이터 샘플을 선택</br>(구하기 쉬운 데이터 사용, 정보 제공 동의를 한 고객 데이터만 사용)
2. `눈덩이 샘플링`: 기존 샘플을 기반으로 미래의 샘플을 선택</br>(임의로 만든 사용자 계정을 만든 후 해당 계정을 팔로우하는 계정을 모두 스크랩)
3. `판단 샘플링`: 전문가가 어떤 샘플을 포함할지 결정
4. `할당 샘플링`: 무작위화 없이 특정 데이터 그룹별 할당량에 의거해 샘플 선택</br>(설문조사 시, 실제 연령에 상관없이 각 연령 그룹마다 응답 100개씩 수집)

### 4.1.2. 단순 무작위 샘플링

- 가장 단순한 형태의 무작위 샘플링은 각 샘플이 선택될 확률이 모두 동일하다.
- 구현이 쉬우나, 드물게 발생하는 범주의 데이터가 포함되지 않을 수 있다.

### 4.1.3. 계층적 샘플링

- 모집단을 상이한 성질의 그룹으로 나눈 뒤, 각 그룹에 개별적으로 샘플링을 수행한다.
- 아무리 드물게 발생하더라도 해당 클래스의 샘플이 포함된다.
- 항상 가능하지는 않다.(ex. 어떤 샘플은 A, B 클래스에 모두 속할 수 있다.)

### 4.1.4. 가중 샘플링

- 각 샘플에 가중치가 있어, 이를 기반으로 샘플이 선택될 확률이 결정된다.
- 도메인 전문 지식을 적용할 수 있다.
- 선택 확률을 높이고 싶다면 더 높은 가중치를 부여한다.
- 샘플 가중치(ML): 가중치가 높은 샘플은 손실함수에 더 많은 영향을 주어 모델의 결정 경계를 변화시킨다.
<p align="center"><img width="400" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/883af7e0-6f10-48ca-9909-0a9d04109eca"></p>

### 4.1.5. 저수지 샘플링

- 프로덕션 환경의 스트리밍 데이터를 처리할 때 특히 유용한 알고리즘
- example
    - 지속적으로 수집되는 트윗 스트림에서 분석/훈련을 위해 k개의 트윗을 샘플링하기
    - 요구사항
        - 각 트윗이 선택될 확률은 동일
        - 알고리즘 가동을 언제든지 멈출 수 있으며 이때 각 트윗이 올바른 확률로 샘플링 됐음을 보장해야함
    - 솔루션
        - 알고리즘은 배열 형태로 구현 가능한 저장소를 포함한다.
        1. 첫 k개의 요소를 저장소에 넣는다.
        2. 수집되는 각 n번째 요소마다 1<=i<=n을 만족하는 난수 i를 생성한다.
        3. 1<=i<=k라면 저장소의 i번째 요소를 n번째 요소로 교체한다. 아니라면 다음 요소로 넘어간다.
    - 결과
        - 수집되는 각 n번째 요소가 저장소에 포함될 확률이 k/n임을 뜻한다.(각 샘플이 선택될 확률 동일)
<p align="center"><img width="600" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/57225c71-f621-44ff-82a5-7175807c2aad"></p>

### 4.1.6. 중요도 샘플링

- 원하는 분포가 아닌 다른 확률 분포만 사용 가능한 상황에서, 원하는 확률 분포에서의 샘플링이 가능하다.
- example
    - 확률분포 P에서 x를 샘플링해야하는데, P는 샘플링 비용이 크고 느리며 활용이 어렵다. </br> 반면, 확률분포 Q는 샘플링하기 훨씬 쉽다.
    - x를 Q에서 대신 샘플링하고, 해당 샘플의 가중치를 P/Q로 부여한다.
    - Q = 제안분포, 중요도 분포
- 정책 기반 강화학습(ML)
    - 새로운 정책의 가치함수를 추정하고자 할 때, 행동에 따르는 총 보상을 계산하는 일은 비용이 크다. </br> 이때, 이전 정책과 유사성이 크면, 이전 정책을 기반으로 총 보상을 계산하고 새로운 정책에 따른 가중치로 재조정하는 방법을 사용할 수 있다.

## 4.2. 레이블링

### 4.2.1. 수작업 레이블

- 단점
    1. 비용이 크다.
    2. 개인 정보 보호 문제를 야기한다.
    3. 느리다.
    4. 레이블 다중성
        - 기업에서는 충분한 데이터를 얻기 위해 여러 소스로부터 데이터를 수집하고, 전문 지식수준이 상이한 어노테이터들을 고용한다.
        - 이로인해, 하나의 데이터에 레이블이 복수로 존재하는 문제 발생
        - 어노테이터 간 서로 불일치하는 레이블 문제를 최소화하기 위해, 문제를 정확히 정의해야 한다.
- 데이터 계보
    - 서로 다른 어노테이터가 생성한 다양한 소스의 데이터를 품질 고민없이 사용하면 문제 발생
        - ex. 원본 데이터보다 훨씬 낮은 정확도로 레이블링하면 모델 성능이 감소한다.
    - 데이터 계보 기법: 각 데이터 샘플과 레이블의 출처를 가능하게 설정하는 것
    - 데이터 내 잠재 편향에 플래그를 할당하고 모델을 디버깅하는 데 큰 도움이 된다. 

### 4.2.2. 자연 레이블

- 자연적인 Groud Truth Label이 존재하는 경우, 작업이 훨씬 수월하다.
- ex. 2분후 주식 가격 예측 모델: 실제로 2분이 지난 후, 예측한 가격과 실제 가격을 비교해보면 된다.
- ex. 기계번역 후, 번역이 적절하지 않으면 사용자 커뮤니티에서 다른 번역을 제출할 수 있도록 옵션을 마련한다.
- 쉽고 저렴한 방법이다.
- 자연 레이블 방식 사용 중에, 일정 시간이 지나도 레이블을 얻지 못하면 음성레이블, 암시적 레이블이라 부른다. </br> 레이블을 얻으면 양성 레이블, 명시적 레이블이라 부른다.
- 피드백 루프 길이: 예측을 수행한 시점부터 피드백을 얻는 시점까지 걸리는 시간
    - 피드백을 포착할 window 길이 결정은 신중히해야함 → 속도와 정확도 사이에 trade-off가 존재한다.

### 4.2.3. 레이블 부족 문제 해결하기

<p align="center"><img width="750" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/a3f035b8-7027-4e58-9940-4372155de0d2"></p>

#### 약한 지도학습

- 수작업 레이블을 아예 사용하지 않는 방법
- 레이블링 할 때, 도메인 전문 지식을 통해 개발된 휴리스틱을 활용
- 레이블링 함수(LF) 개념을 기반으로 한다.(키워드 휴리스틱, 정규표현식, 데이터베이스 조회, 다른 모델의 출력)
    - `프로그래밍 방식 레이블링`이라고도 한다. 
    - ex. 간호사 노트에 '위급'이라고 적혀있으면 위험군으로 분류
- 장점
    - 데이터에 개인 정보 보호 요구 사항이 엄격하게 적용될 때 특히 유용하다.
        - 일부 데이터만 확인하여 LF를 작성한 뒤 해당 함수를 나머지 데이터에 비공개로 적용한다.
    - 도메인 전문 지식을 버전에 지정하고 그것을 재사용하거나 공유할 수 있다.
- 단점
    - LF가 데이터 샘플 전체를 다루지 못할 수 있다. 이 경우, LF로 레이블링 후 ML모델로 훈련하고 샘플에 해당 모델을 적용한다.
    - 약한 지도 학습으로 얻은 레이블은 실제로 적용하기엔 잡음이 너무 많을 때가 있다.
<p align="center"><img width="750" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/8b94c68c-9c92-47ea-8103-71d41a22b412"></p>

#### 준지도 학습

- 구조적인 가정을 활용해 초기에 수집한 소수의 레이블을 기반으로 새로운 레이블을 생성한다.
- 초기에는 레이블이 붙은 데이터가 필요하다.
- 준지도 학습 방법
    - 자가훈련(semi-supervised learning)
        - 먼저 레이블이 지정된 기존 데이터로 모델 학습을 시작한 뒤 해당 모델로 레이블이 미지정된 샘플에 예측을 수행한다.
        - 샘플의 원시 확률 점수가 높다면 예측이 정확하다고 가정하고, 높은 확률로 예측한 레이블은 훈련세트에 추가한다.
        - 확장한 훈련세트로 신규 모델을 훈련한다.(반복)
    - 유사한 특성이 있는 데이터 샘플끼리는 레이블이 동일하다고 가정
        - KNN이나 클러스터링 방법을 사용하여 동일한 클러스터에 속하는 샘플을 찾아낸다.

#### 전이학습(Transfer Learning)

- 특정 작업을 위해 개발된 모델을 시작점으로 삼아, 후속 작업에 재사용하는 일련의 방법론
- 과정
    1. 기본적인 작업을 대상으로 기본 모델 학습: 훈련데이터 양이 많고 수집비용이 낮은 작업
    2. 미세조정(fine tuning): 훈련된 모델을 관심있는 다운스트림 작업에 사용. </br> 기본 모델에 훈련을 계속 이어나가는 등 기본 모델 일부를 변경하는 일
- 데이터가 많지 않은 작업에 적합
- 사전 훈련한 모델을 사용하면 처음부터 모델을 직접 훈련하는 것보다 성능이 큰 폭으로 향상됨

#### 능동적 학습(Active Learning)

- ML 모델이 학습할 데이터 샘플을 선택하여 질의하면, 어노테이터가 그것에 레이블을 지정한다.
- 데이터 샘플을 무작위로 골라 레이블링하는 것이 아닌, 특정 지표나 휴리스틱에 근거해 모델에 가장 필요한 샘플을 선택해 레이블링한다.
- example
    - 불확실성과 같은 요소를 지표로 삼으면, 결정경계가 더 잘 학습된다.
    - 다양한 후보 모델 간의 불일치를 기반으로, 불일치 정도가 가장 큰 샘플을 선택하여 레이블링한다.
    - 그래디언트 업데이트가 가장 크거나 손실을 가장 크게 줄이는 샘플을 선택하여 레이블링한다.
- 장점
    - 더 적은 데이터로 더 높은 정확도를 달성할 수 있다.
    - 데이터 레이블링 작업의 효율성을 향상한다.



---

## 💬 이야기 주제

> <strong><i>🐧: 왜 펭귄은 귀여울까요?</i></strong>
