<div align="center">
    <h1>4장. 훈련 데이터</h1>
    <i>moderated by <a href="https://github.com/bsm8734">샐리</a></i>
</div>

## 📝 목차

- [💬 이야기 주제](#-이야기-주제)

(⭐️ 작성 후에 목차도 추가해주세요!)

---

## 4.1. 샘플링

- 샘플링을 하면 작업을 빠르게 수행할 수 있고, 비용이 줄어든다.

### 4.1.1. 비확률 샘플링

- 데이터를 확률이 아닌 기준에 의거해 선택하는 방법
- 실데이터를 잘 대표하지 못하고 선택 편향이 강하지만, 사용이 편리하여 많이 사용된다.

1. `편의 샘플링`: 가용성에 의거해 데이터 샘플을 선택</br>(구하기 쉬운 데이터 사용, 정보 제공 동의를 한 고객 데이터만 사용)
2. `눈덩이 샘플링`: 기존 샘플을 기반으로 미래의 샘플을 선택</br>(임의로 만든 사용자 계정을 만든 후 해당 계정을 팔로우하는 계정을 모두 스크랩)
3. `판단 샘플링`: 전문가가 어떤 샘플을 포함할지 결정
4. `할당 샘플링`: 무작위화 없이 특정 데이터 그룹별 할당량에 의거해 샘플 선택</br>(설문조사 시, 실제 연령에 상관없이 각 연령 그룹마다 응답 100개씩 수집)

### 4.1.2. 단순 무작위 샘플링

- 가장 단순한 형태의 무작위 샘플링은 각 샘플이 선택될 확률이 모두 동일하다.
- 구현이 쉬우나, 드물게 발생하는 범주의 데이터가 포함되지 않을 수 있다.

### 4.1.3. 계층적 샘플링

- 모집단을 상이한 성질의 그룹으로 나눈 뒤, 각 그룹에 개별적으로 샘플링을 수행한다.
- 아무리 드물게 발생하더라도 해당 클래스의 샘플이 포함된다.
- 항상 가능하지는 않다.(ex. 어떤 샘플은 A, B 클래스에 모두 속할 수 있다.)

### 4.1.4. 가중 샘플링

- 각 샘플에 가중치가 있어, 이를 기반으로 샘플이 선택될 확률이 결정된다.
- 도메인 전문 지식을 적용할 수 있다.
- 선택 확률을 높이고 싶다면 더 높은 가중치를 부여한다.
- 샘플 가중치(ML): 가중치가 높은 샘플은 손실함수에 더 많은 영향을 주어 모델의 결정 경계를 변화시킨다.
<p align="center"><img width="400" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/883af7e0-6f10-48ca-9909-0a9d04109eca"></p>

### 4.1.5. 저수지 샘플링

- 프로덕션 환경의 스트리밍 데이터를 처리할 때 특히 유용한 알고리즘
- example
    - 지속적으로 수집되는 트윗 스트림에서 분석/훈련을 위해 k개의 트윗을 샘플링하기
    - 요구사항
        - 각 트윗이 선택될 확률은 동일
        - 알고리즘 가동을 언제든지 멈출 수 있으며 이때 각 트윗이 올바른 확률로 샘플링 됐음을 보장해야함
    - 솔루션
        - 알고리즘은 배열 형태로 구현 가능한 저장소를 포함한다.
        1. 첫 k개의 요소를 저장소에 넣는다.
        2. 수집되는 각 n번째 요소마다 1<=i<=n을 만족하는 난수 i를 생성한다.
        3. 1<=i<=k라면 저장소의 i번째 요소를 n번째 요소로 교체한다. 아니라면 다음 요소로 넘어간다.
    - 결과
        - 수집되는 각 n번째 요소가 저장소에 포함될 확률이 k/n임을 뜻한다.(각 샘플이 선택될 확률 동일)
<p align="center"><img width="600" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/57225c71-f621-44ff-82a5-7175807c2aad"></p>

### 4.1.6. 중요도 샘플링

- 원하는 분포가 아닌 다른 확률 분포만 사용 가능한 상황에서, 원하는 확률 분포에서의 샘플링이 가능하다.
- example
    - 확률분포 P에서 x를 샘플링해야하는데, P는 샘플링 비용이 크고 느리며 활용이 어렵다. </br> 반면, 확률분포 Q는 샘플링하기 훨씬 쉽다.
    - x를 Q에서 대신 샘플링하고, 해당 샘플의 가중치를 P/Q로 부여한다.
    - Q = 제안분포, 중요도 분포
- 정책 기반 강화학습(ML)
    - 새로운 정책의 가치함수를 추정하고자 할 때, 행동에 따르는 총 보상을 계산하는 일은 비용이 크다. </br> 이때, 이전 정책과 유사성이 크면, 이전 정책을 기반으로 총 보상을 계산하고 새로운 정책에 따른 가중치로 재조정하는 방법을 사용할 수 있다.

## 4.2. 레이블링

### 4.2.1. 수작업 레이블

- 단점
    1. 비용이 크다.
    2. 개인 정보 보호 문제를 야기한다.
    3. 느리다.
    4. 레이블 다중성
        - 기업에서는 충분한 데이터를 얻기 위해 여러 소스로부터 데이터를 수집하고, 전문 지식수준이 상이한 어노테이터들을 고용한다.
        - 이로인해, 하나의 데이터에 레이블이 복수로 존재하는 문제 발생
        - 어노테이터 간 서로 불일치하는 레이블 문제를 최소화하기 위해, 문제를 정확히 정의해야 한다.
- 데이터 계보
    - 서로 다른 어노테이터가 생성한 다양한 소스의 데이터를 품질 고민없이 사용하면 문제 발생
        - ex. 원본 데이터보다 훨씬 낮은 정확도로 레이블링하면 모델 성능이 감소한다.
    - 데이터 계보 기법: 각 데이터 샘플과 레이블의 출처를 가능하게 설정하는 것
    - 데이터 내 잠재 편향에 플래그를 할당하고 모델을 디버깅하는 데 큰 도움이 된다. 

### 4.2.2. 자연 레이블

- 자연적인 Groud Truth Label이 존재하는 경우, 작업이 훨씬 수월하다.
- ex. 2분후 주식 가격 예측 모델: 실제로 2분이 지난 후, 예측한 가격과 실제 가격을 비교해보면 된다.
- ex. 기계번역 후, 번역이 적절하지 않으면 사용자 커뮤니티에서 다른 번역을 제출할 수 있도록 옵션을 마련한다.
- 쉽고 저렴한 방법이다.
- 자연 레이블 방식 사용 중에, 일정 시간이 지나도 레이블을 얻지 못하면 음성레이블, 암시적 레이블이라 부른다. </br> 레이블을 얻으면 양성 레이블, 명시적 레이블이라 부른다.
- 피드백 루프 길이: 예측을 수행한 시점부터 피드백을 얻는 시점까지 걸리는 시간
    - 피드백을 포착할 window 길이 결정은 신중히해야함 → 속도와 정확도 사이에 trade-off가 존재한다.

### 4.2.3. 레이블 부족 문제 해결하기

<p align="center"><img width="750" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/a3f035b8-7027-4e58-9940-4372155de0d2"></p>

#### 약한 지도학습

- 수작업 레이블을 아예 사용하지 않는 방법
- 레이블링 할 때, 도메인 전문 지식을 통해 개발된 휴리스틱을 활용
- 레이블링 함수(LF) 개념을 기반으로 한다.(키워드 휴리스틱, 정규표현식, 데이터베이스 조회, 다른 모델의 출력)
    - `프로그래밍 방식 레이블링`이라고도 한다. 
    - ex. 간호사 노트에 '위급'이라고 적혀있으면 위험군으로 분류
- 장점
    - 데이터에 개인 정보 보호 요구 사항이 엄격하게 적용될 때 특히 유용하다.
        - 일부 데이터만 확인하여 LF를 작성한 뒤 해당 함수를 나머지 데이터에 비공개로 적용한다.
    - 도메인 전문 지식을 버전에 지정하고 그것을 재사용하거나 공유할 수 있다.
- 단점
    - LF가 데이터 샘플 전체를 다루지 못할 수 있다. 이 경우, LF로 레이블링 후 ML모델로 훈련하고 샘플에 해당 모델을 적용한다.
    - 약한 지도 학습으로 얻은 레이블은 실제로 적용하기엔 잡음이 너무 많을 때가 있다.
<p align="center"><img width="750" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/8b94c68c-9c92-47ea-8103-71d41a22b412"></p>

#### 준지도 학습

- 구조적인 가정을 활용해 초기에 수집한 소수의 레이블을 기반으로 새로운 레이블을 생성한다.
- 초기에는 레이블이 붙은 데이터가 필요하다.
- 준지도 학습 방법
    - 자가훈련(semi-supervised learning)
        - 먼저 레이블이 지정된 기존 데이터로 모델 학습을 시작한 뒤 해당 모델로 레이블이 미지정된 샘플에 예측을 수행한다.
        - 샘플의 원시 확률 점수가 높다면 예측이 정확하다고 가정하고, 높은 확률로 예측한 레이블은 훈련세트에 추가한다.
        - 확장한 훈련세트로 신규 모델을 훈련한다.(반복)
    - 유사한 특성이 있는 데이터 샘플끼리는 레이블이 동일하다고 가정
        - KNN이나 클러스터링 방법을 사용하여 동일한 클러스터에 속하는 샘플을 찾아낸다.

#### 전이학습(Transfer Learning)

- 특정 작업을 위해 개발된 모델을 시작점으로 삼아, 후속 작업에 재사용하는 일련의 방법론
- 과정
    1. 기본적인 작업을 대상으로 기본 모델 학습: 훈련데이터 양이 많고 수집비용이 낮은 작업
    2. 미세조정(fine tuning): 훈련된 모델을 관심있는 다운스트림 작업에 사용. </br> 기본 모델에 훈련을 계속 이어나가는 등 기본 모델 일부를 변경하는 일
- 데이터가 많지 않은 작업에 적합
- 사전 훈련한 모델을 사용하면 처음부터 모델을 직접 훈련하는 것보다 성능이 큰 폭으로 향상됨

#### 능동적 학습(Active Learning)

- ML 모델이 학습할 데이터 샘플을 선택하여 질의하면, 어노테이터가 그것에 레이블을 지정한다.
- 데이터 샘플을 무작위로 골라 레이블링하는 것이 아닌, 특정 지표나 휴리스틱에 근거해 모델에 가장 필요한 샘플을 선택해 레이블링한다.
- example
    - 불확실성과 같은 요소를 지표로 삼으면, 결정경계가 더 잘 학습된다.
    - 다양한 후보 모델 간의 불일치를 기반으로, 불일치 정도가 가장 큰 샘플을 선택하여 레이블링한다.
    - 그래디언트 업데이트가 가장 크거나 손실을 가장 크게 줄이는 샘플을 선택하여 레이블링한다.
- 장점
    - 더 적은 데이터로 더 높은 정확도를 달성할 수 있다.
    - 데이터 레이블링 작업의 효율성을 향상한다.

## 4.3. 클래스 불균형 문제

- 훈련 데이터 내 클래스당 샘플 개수가 크게 차이 나는 문제

### 4.3.1. 클래스 불균형 문제의 어려움

- 딥러닝이 클래스 불균형이 심한 경우에 잘 작동하지 않는 이유
    1. 드물게 발생하는 클래스의 데이터 포인트가 훈련셋에 포함되지 못할 수 있다. 해당 클래스가 존재하지 않는다고 가정하게된다.
    2. 모델이 데이터에 내재하는 유용한 패턴을 학습하는 대신 단순 휴리스틱을 활용하려는 경향이 강해져, 최적이 아닌 해를 고집한다.
    3. 비대칭적인 오차 비용 문제로 이어진다. 드물게 발생하는 클래스 샘플을 잘못 예측해서 발생하는 비용이 일반적인 샘플에 비해 더 크다.</br> 대다수의 작업에서는 드물게 발생하는 사건을 탐지하는 일이 주 목적이다.(ex. 이상거래탐지)

### 4.3.2. 클래스 불균형 처리하기

- 불균형에 대한 민감도가 문제의 복잡도에 따라 증가하며, 복잡도가 낮고 선형으로 분리 가능한 문제는 클래스 불균형 정도에 상관없이 영향받지 않는다.
- 신경망이 더 크고 기어질수록 클래스 불균형을 일부러 수정해서는 안된다는 주장이 존재(실 불균형을 반영해야한다는 주장)

#### 올바른 평가 지표 사용하기

- 정확도와 오차비율은 성능을 보고하는 데 사용하는 주된 지표이나, 불균형 클래스에 부적절(모든 클래스를 동일하게 취급하므로)
- 정밀도, 재현율, F1, ROC 곡선 아래 면적(AUC)은 비대칭 지표이다.
    - 임곗값을 조정하여 진양성률(재현율), 위양성률(오경보 확률) 조정이 가능하다.
    - F1, 재현율, ROC는 양성클래스에만 초점을 맞추고, 모델이 음성 클래스에서 얼마나 잘 작동하는지는 관심없다.
    - 클래스 불균형이 심할 때, 이들이 더 유용한 정보를 담고있다고 볼 수 있다.
<p align="center"><img width="600" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/c8b83aad-1f5f-4013-adbd-b0b7ed55645f"></p>

#### 데이터 수준의 방법: 리샘플링

- 훈련 데이터의 분포를 수정해 불균형 정도를 줄여서 모델 학습을 더 용이하게 만드는 방법
- 훈련 데이터를 리샘플링한다면 리샘플링된 데이터에서 모델을 평가하지 않아야함 → 리샘플링한 분포에 모델이 과적합될 수 있음
- 언더샘플링은 데이터 제거 과정에서 중요한 데이터가 손실될 위험이 있으며, 오버샘플링은 훈련 데이터에 과적합될 위험이 있다.
- 저차원의 데이터를 오버샘플링하는 방법(저차원 데이터에서만 효과적)
    - 토멕 링크
    - 소수 클래스 합성을 통한 오버샘플링 기법(SMOTE)
- 언더샘플링
    - 2단계 학습
    - 동적 샘플링
<p align="center"><img width="604" alt="image" src="https://github.com/boost-devs/book-study/assets/35002768/dcac8521-a67d-49d2-8093-4baa2e67b014"></p>

#### 알고리즘 수준의 방법

- 학습 데이터 분포를 그대로 유지하면서 클래스 불균형에 더 강건한 알고리즘으로 변경하는 것
- 비용 민감 학습: 클래스 마다 서로 다른 비용을 고려해 각 손실값을 수정
- 클래스 균형 손실: 불균형 데이터셋으로 훈련한 모델은 다수 클래스에 편향된다. </br>이러한 편향을 바로잡기 위해 소수 클래스를 잘못 예측한 모델에 불이익을 준다.
- 초점 손실: 모델이 분류하기 어려운 샘플을 집중적으로 학습하도록 인센티브를 준다.

## 4.4. 데이터 증강

### 4.4.1. 단순 레이블 보존 변환

- 레이블을 유지한채 이미지를 무작위로 수정하는 방법(사실상 계산비용 = 0)

### 4.4.2. 교란

- 레이블을 보존하지만 종종 모델이 잘못된 예측을 하도록 속인다.
- 적대적 공격: 잡음을 넣어 신경망이 잘못된 예측을 하도록하는 것
- 모델이 학습한 결정 경계에서 약점을 인식하고 성능을 개선하는데 도움이 된다.
- ex. 이미지 해상도가 높은 경우

### 4.4.3. 데이터 합성

- 일부 훈련 데이터를 합성하여 모델 성능을 높인다.
- ex. NLP에서 템플릿을 사용해 낮은 비용으로 모델을 부트스트랩한다.

---

## 💬 이야기 주제

> <strong><i>🐧: 왜 펭귄은 귀여울까요?</i></strong>
